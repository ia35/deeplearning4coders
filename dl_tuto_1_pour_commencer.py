# -*- coding: utf-8 -*-
"""dl_tuto_1_pour_commencer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YlUk6IfszhsGHPTCysmowl3J9hiDpjZy

# Pour commencer

---

## Destinataires de ce blog
Ce tutoriel est destiné aux informaticiens, aux statisticiens, aux ingénieurs et plus généralement à tous ceux qui veulent se former au Deep Learning (apprentissage profond) à l'aide d'exemples logiciels. Il n'y aura pas de discussion théorique sur les bénéfices de telle ou telle méthode. L'approche est "apprendre en codant"

Ces cours sont fortement inspirés de ceux de [fastai](https://course.fast.ai/index.html), @jeremyphoward.

##Conventions
Il est probable, que de temps en temps, notamment dans les premiers tutoriels, vous rencontriez des expressions, des termes, des noms d'outils que vous ne connaissez pas. 

Ceux-ci sont généralement expliqués et commentés, sur mon site http://intelligence-artificielle.agency/ 

Par exemple, je ne décris pas Anaconda dans mes tutoriels car c'est inutile avec Colaboratory mais je le présente sur mon [site](http://intelligence-artificielle.agency/lexique/).

## Prérequis
###Python 3

Il faut savoir coder, de préférence en Python et encore mieux avec Python 3.
Si vous ne le savez pas, mais que vous connaissez un autre langage de programmation, alors vous pourrez (peut-être) suivre ces tutoriels, mais vous devrez probablement, de temps en temps, vous former à quelques aspects spécifiques du langage.

Vous trouverez ici quelques [ressources](https://forums.fast.ai/t/recommended-python-learning-resources/26888). 

Pour ne pas être exclusif à Google et fastai, notez qu'il y a aussi de très bons tutoriels Python chez [Microsoft Azure](https://notebooks.azure.com/#).

###Environnement
Soit vous utilisez [Google Colaboratory,](https://colab.research.google.com/notebooks/welcome.ipynb) ce que je recommande fortement puisqu'ill vous permet d'écrire et d'exécuter du code, de le sauvegarder et le partager gratuitement, depuis votre navigateur. 

Colab utilise [Jupyter](https://jupyter.org) (ce que je fais systématiquement) et vous permet, cerise sur le gâteau, de bénéficier gratuitement de GPU et même TPU.

Mais si pour une raison que j'ignore, vous préférez travaillez en local ou avec d'autres [ressources](http://intelligence-artificielle.agency/le-cloud-pour-le-deep-learning/), alors installez [Anaconda](http://intelligence-artificielle.agency/anaconda/).

###Packages
J'utilise de nombreux packages Python, ceux qui sont relatifs à la Data Science. Parmi ceux-là, [NumPy](https://www.numpy.org), [Pandas](https://pandas.pydata.org), [Matplotlib](https://matplotlib.org), [Scikit-Learn](https://scikit-learn.org/stable/).

## CPU / GPU / TPU
Difficile de se former sérieusement au DL sans utiliser au minimum des GPU (graphical processing units) au lieu de CPU (computing processing units). Avec Colab, vous pouvez même disposer de TPU (Tensor Processing Unit)

Les GPU sont, la plupart du temps, ceux de [NVIDIA](https://www.nvidia.com/fr-fr/about-nvidia/ai-computing/). Ils utilisent l’architecture de traitement parallèle [CUDA](https://www.nvidia.fr/object/cuda-parallel-computing-fr.html).

Pour ceux qui veulent savoir pourquoi les GPU sont plus performants que les CPU, c'est [ici](https://www.quora.com/Why-are-GPUs-well-suited-to-deep-learning). Le résumé est que les GPU sont meilleurs que les CPU pour faire du calcul matriciel, or c'est l'essentiel des calculs en DL et pour ceux qui s'intéressent aux TPU, c'est [ici](https://cloud.google.com/blog/products/ai-machine-learning/what-makes-tpus-fine-tuned-for-deep-learning). 

Lorsque vous exécutez un notebook sous Colab, n'oubliez pas de modifier le type d'exécution en GPU (ou TPU) :  *Exécution/Modifier le type d'exécution/GPU*

# Framework

Le choix le plus difficile à faire est celui du framework, c'est à dire de l'outil d'apprentissage automatique. 

Faut-il choisir TensorFlow, PyTorch, CNTK, Mxnet, Caffe2, … Gluon, Keras, fastai, ... 

Mes critères de [choix](https://en.wikipedia.org/wiki/Comparison_of_deep-learning_software) sont les suivants : 

1.   l'outil doit-être Open Source
2.   il doit disposer d'une API Python
3.   il doit avoir une forte communauté
4.   il doit être bien documenté
5.   il doit supporter CUDA

A partir de ces critères, il reste deux choix importants : TensorFlow et PyTorch.
Les deux avantages principaux de TensorFlow sont :

1.   sa très forte communauté, bien supérieure à celle de Pytorch,
2.   et le support de Keras

La force de PyTorch est fastai car ce sont les meilleurs cours en ligne gratuits sur le DL.

Devant l'impossibilité de faire un choix radical, j'utiliserai les deux : [TensorFlow](https://www.tensorflow.org) avec [Keras](https://keras.io) et [PyTorch](https://pytorch.org) avec [fastai](https://www.fast.ai).
"""

